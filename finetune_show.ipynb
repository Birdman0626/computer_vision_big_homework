{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 10:21:43.097091: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, GroundingDinoForObjectDetection,GroundingDinoConfig\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from Huggingface_agent.finetune.loss_utils import loss_helper\n",
    "from Huggingface_agent.finetune.finetune_utils import get_finetune_model, get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\" \n",
    "processor = AutoProcessor.from_pretrained('./model')\n",
    "config = GroundingDinoConfig(bbox_loss_coefficient = 10.0, giou_loss_coefficient = 10.0)\n",
    "model = GroundingDinoForObjectDetection.from_pretrained('./model',config=config).to(device)\n",
    "finetune_model = get_finetune_model(model,device)\n",
    "train_dataset = get_dataset()\n",
    "\n",
    "def data_collator(batch:list[dict]):\n",
    "        paths = [ image['image_path'] for image in batch]\n",
    "        Images = [Image.open(f\"./{i}\").convert(\"RGB\") for i in paths]\n",
    "        text = ['an interface. an icon.' for _ in range(len(paths))]\n",
    "        inputs = processor(images=Images, text=text,return_tensors='pt').to(device)\n",
    "        inputs['labels'] = {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'target_sizes': [image.size[::-1] for image in Images],\n",
    "            'bbox': [image['range'] for image in batch],\n",
    "            'icon_num': [image['icon_num'] for image in batch] \n",
    "        }\n",
    "        return inputs\n",
    "\n",
    "def loss(outputs, labels, **kwargs):\n",
    "    # Training with box threshold is zero.\n",
    "    res = processor.post_process_grounded_object_detection(\n",
    "        outputs,\n",
    "        labels['input_ids'],\n",
    "        box_threshold=0.,\n",
    "        text_threshold=0.,\n",
    "        target_sizes=[i[::-1] for i in labels['target_sizes']]\n",
    "    )\n",
    "    return loss_helper(res, labels, device)\n",
    "\n",
    "train_args = TrainingArguments(\n",
    "        output_dir='./ckpt',\n",
    "        do_train=True,\n",
    "        do_eval=False,\n",
    "        per_device_train_batch_size=1,\n",
    "        num_train_epochs=20,\n",
    "        save_steps=50,\n",
    "        # log_level = 'info',\n",
    "        logging_steps=20,\n",
    "        torch_empty_cache_steps=500,\n",
    "        learning_rate=5e-1,\n",
    "        report_to = \"tensorboard\",\n",
    "        remove_unused_columns=False,\n",
    "        dataloader_pin_memory=False,\n",
    "        use_cpu = True if not torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = finetune_model,\n",
    "    args = train_args,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=processor,\n",
    "    data_collator=data_collator,\n",
    "    compute_loss_func=loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GroundingDinoForObjectDetection(\n",
       "  (model): GroundingDinoModel(\n",
       "    (backbone): GroundingDinoConvModel(\n",
       "      (conv_encoder): GroundingDinoConvEncoder(\n",
       "        (model): SwinBackbone(\n",
       "          (embeddings): SwinEmbeddings(\n",
       "            (patch_embeddings): SwinPatchEmbeddings(\n",
       "              (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "            )\n",
       "            (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (encoder): SwinEncoder(\n",
       "            (layers): ModuleList(\n",
       "              (0): SwinStage(\n",
       "                (blocks): ModuleList(\n",
       "                  (0): SwinLayer(\n",
       "                    (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attention): SwinAttention(\n",
       "                      (self): SwinSelfAttention(\n",
       "                        (query): Linear(in_features=96, out_features=96, bias=True)\n",
       "                        (key): Linear(in_features=96, out_features=96, bias=True)\n",
       "                        (value): Linear(in_features=96, out_features=96, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                      (output): SwinSelfOutput(\n",
       "                        (dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (drop_path): Identity()\n",
       "                    (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "                    (intermediate): SwinIntermediate(\n",
       "                      (dense): Linear(in_features=96, out_features=384, bias=True)\n",
       "                      (intermediate_act_fn): GELUActivation()\n",
       "                    )\n",
       "                    (output): SwinOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=96, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (1): SwinLayer(\n",
       "                    (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attention): SwinAttention(\n",
       "                      (self): SwinSelfAttention(\n",
       "                        (query): Linear(in_features=96, out_features=96, bias=True)\n",
       "                        (key): Linear(in_features=96, out_features=96, bias=True)\n",
       "                        (value): Linear(in_features=96, out_features=96, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                      (output): SwinSelfOutput(\n",
       "                        (dense): Linear(in_features=96, out_features=96, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (drop_path): SwinDropPath(p=0.00909090880304575)\n",
       "                    (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "                    (intermediate): SwinIntermediate(\n",
       "                      (dense): Linear(in_features=96, out_features=384, bias=True)\n",
       "                      (intermediate_act_fn): GELUActivation()\n",
       "                    )\n",
       "                    (output): SwinOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=96, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (downsample): SwinPatchMerging(\n",
       "                  (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "                  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (1): SwinStage(\n",
       "                (blocks): ModuleList(\n",
       "                  (0): SwinLayer(\n",
       "                    (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attention): SwinAttention(\n",
       "                      (self): SwinSelfAttention(\n",
       "                        (query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                        (key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                        (value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                      (output): SwinSelfOutput(\n",
       "                        (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (drop_path): SwinDropPath(p=0.0181818176060915)\n",
       "                    (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                    (intermediate): SwinIntermediate(\n",
       "                      (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                      (intermediate_act_fn): GELUActivation()\n",
       "                    )\n",
       "                    (output): SwinOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (1): SwinLayer(\n",
       "                    (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attention): SwinAttention(\n",
       "                      (self): SwinSelfAttention(\n",
       "                        (query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                        (key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                        (value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                      (output): SwinSelfOutput(\n",
       "                        (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (drop_path): SwinDropPath(p=0.027272727340459824)\n",
       "                    (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                    (intermediate): SwinIntermediate(\n",
       "                      (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                      (intermediate_act_fn): GELUActivation()\n",
       "                    )\n",
       "                    (output): SwinOutput(\n",
       "                      (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (downsample): SwinPatchMerging(\n",
       "                  (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "                  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (2): SwinStage(\n",
       "                (blocks): ModuleList(\n",
       "                  (0): SwinLayer(\n",
       "                    (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attention): SwinAttention(\n",
       "                      (self): SwinSelfAttention(\n",
       "                        (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                      (output): SwinSelfOutput(\n",
       "                        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (drop_path): SwinDropPath(p=0.036363635212183)\n",
       "                    (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                    (intermediate): SwinIntermediate(\n",
       "                      (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                      (intermediate_act_fn): GELUActivation()\n",
       "                    )\n",
       "                    (output): SwinOutput(\n",
       "                      (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (1): SwinLayer(\n",
       "                    (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attention): SwinAttention(\n",
       "                      (self): SwinSelfAttention(\n",
       "                        (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                      (output): SwinSelfOutput(\n",
       "                        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (drop_path): SwinDropPath(p=0.045454543083906174)\n",
       "                    (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                    (intermediate): SwinIntermediate(\n",
       "                      (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                      (intermediate_act_fn): GELUActivation()\n",
       "                    )\n",
       "                    (output): SwinOutput(\n",
       "                      (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (2): SwinLayer(\n",
       "                    (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attention): SwinAttention(\n",
       "                      (self): SwinSelfAttention(\n",
       "                        (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                      (output): SwinSelfOutput(\n",
       "                        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (drop_path): SwinDropPath(p=0.054545458406209946)\n",
       "                    (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                    (intermediate): SwinIntermediate(\n",
       "                      (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                      (intermediate_act_fn): GELUActivation()\n",
       "                    )\n",
       "                    (output): SwinOutput(\n",
       "                      (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (3): SwinLayer(\n",
       "                    (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attention): SwinAttention(\n",
       "                      (self): SwinSelfAttention(\n",
       "                        (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                      (output): SwinSelfOutput(\n",
       "                        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (drop_path): SwinDropPath(p=0.06363636255264282)\n",
       "                    (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                    (intermediate): SwinIntermediate(\n",
       "                      (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                      (intermediate_act_fn): GELUActivation()\n",
       "                    )\n",
       "                    (output): SwinOutput(\n",
       "                      (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (4): SwinLayer(\n",
       "                    (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attention): SwinAttention(\n",
       "                      (self): SwinSelfAttention(\n",
       "                        (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                      (output): SwinSelfOutput(\n",
       "                        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (drop_path): SwinDropPath(p=0.0727272778749466)\n",
       "                    (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                    (intermediate): SwinIntermediate(\n",
       "                      (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                      (intermediate_act_fn): GELUActivation()\n",
       "                    )\n",
       "                    (output): SwinOutput(\n",
       "                      (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (5): SwinLayer(\n",
       "                    (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attention): SwinAttention(\n",
       "                      (self): SwinSelfAttention(\n",
       "                        (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                      (output): SwinSelfOutput(\n",
       "                        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (drop_path): SwinDropPath(p=0.08181818574666977)\n",
       "                    (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                    (intermediate): SwinIntermediate(\n",
       "                      (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                      (intermediate_act_fn): GELUActivation()\n",
       "                    )\n",
       "                    (output): SwinOutput(\n",
       "                      (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "                (downsample): SwinPatchMerging(\n",
       "                  (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "                  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "              (3): SwinStage(\n",
       "                (blocks): ModuleList(\n",
       "                  (0): SwinLayer(\n",
       "                    (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attention): SwinAttention(\n",
       "                      (self): SwinSelfAttention(\n",
       "                        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                      (output): SwinSelfOutput(\n",
       "                        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (drop_path): SwinDropPath(p=0.09090909361839294)\n",
       "                    (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                    (intermediate): SwinIntermediate(\n",
       "                      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      (intermediate_act_fn): GELUActivation()\n",
       "                    )\n",
       "                    (output): SwinOutput(\n",
       "                      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (1): SwinLayer(\n",
       "                    (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                    (attention): SwinAttention(\n",
       "                      (self): SwinSelfAttention(\n",
       "                        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                      (output): SwinSelfOutput(\n",
       "                        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                        (dropout): Dropout(p=0.0, inplace=False)\n",
       "                      )\n",
       "                    )\n",
       "                    (drop_path): SwinDropPath(p=0.10000000149011612)\n",
       "                    (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                    (intermediate): SwinIntermediate(\n",
       "                      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                      (intermediate_act_fn): GELUActivation()\n",
       "                    )\n",
       "                    (output): SwinOutput(\n",
       "                      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (hidden_states_norms): ModuleDict(\n",
       "            (stage2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (stage3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (stage4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (position_embedding): GroundingDinoSinePositionEmbedding()\n",
       "    )\n",
       "    (input_proj_vision): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (text_backbone): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (text_projection): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (query_position_embeddings): Embedding(900, 256)\n",
       "    (encoder): GroundingDinoEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x GroundingDinoEncoderLayer(\n",
       "          (text_enhancer_layer): GroundingDinoTextEnhancerLayer(\n",
       "            (self_attn): GroundingDinoMultiheadAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (layer_norm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (layer_norm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation): ReLU()\n",
       "          )\n",
       "          (fusion_layer): GroundingDinoFusionLayer(\n",
       "            (layer_norm_vision): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (layer_norm_text): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GroundingDinoBiMultiHeadAttention(\n",
       "              (vision_proj): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (text_proj): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (values_vision_proj): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (values_text_proj): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (out_vision_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (out_text_proj): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            )\n",
       "            (drop_path): GroundingDinoDropPath(p=0.1)\n",
       "          )\n",
       "          (deformable_layer): GroundingDinoDeformableLayer(\n",
       "            (self_attn): GroundingDinoMultiscaleDeformableAttention(\n",
       "              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): ReLU()\n",
       "            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): GroundingDinoDecoder(\n",
       "      (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x GroundingDinoDecoderLayer(\n",
       "          (self_attn): GroundingDinoMultiheadAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn_text): GroundingDinoMultiheadAttention(\n",
       "            (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (encoder_attn_text_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): GroundingDinoMultiscaleDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (reference_points_head): GroundingDinoMLPPredictionHead(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (bbox_embed): ModuleList(\n",
       "        (0-5): 6 x GroundingDinoMLPPredictionHead(\n",
       "          (layers): ModuleList(\n",
       "            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (class_embed): ModuleList(\n",
       "        (0-5): 6 x GroundingDinoContrastiveEmbedding()\n",
       "      )\n",
       "    )\n",
       "    (enc_output): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (enc_output_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder_output_bbox_embed): GroundingDinoMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder_output_class_embed): GroundingDinoContrastiveEmbedding()\n",
       "  )\n",
       "  (bbox_embed): ModuleList(\n",
       "    (0-5): 6 x GroundingDinoMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (class_embed): ModuleList(\n",
       "    (0-5): 6 x GroundingDinoContrastiveEmbedding()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GroundingDinoForObjectDetection.from_pretrained('./model').to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2900' max='2900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2900/2900 40:03, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.137700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.097200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.314600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.966800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.738700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.673600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.613600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.637100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.574800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.609900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.658600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.669800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.688700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.606200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.701100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.633800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.670600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.637000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.720700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.652900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.661700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.618200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.641100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.613500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.742600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.680900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.687400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.604800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.614500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.599700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.564700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.625200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.584700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.623900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.626300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.590700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.564300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.520600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.579400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.550600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.579500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.583800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.636500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.617300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.582100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>1.584300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>1.591700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>1.593900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>1.603700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>1.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>1.696100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>1.586700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>1.671700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.587800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>1.566100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>1.595300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>1.590900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>1.518600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.553100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>1.552700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>1.555400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>1.573100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>1.560200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>1.531300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>1.558100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>1.555800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>1.565700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.549900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>1.515800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>1.593800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>1.610600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>1.593700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.547300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>1.597300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>1.531900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>1.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>1.565700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.582900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>1.591300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>1.572400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>1.528100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>1.575100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.559100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>1.594400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>1.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>1.617900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>1.549600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.611100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>1.514100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>1.605300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>1.539200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>1.537700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>1.612800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>1.573200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>1.539500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>1.601800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.520800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>1.619400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>1.557400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>1.598100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>1.553400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.569600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>1.558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>1.582100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>1.551500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>1.558800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.564700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>1.606700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>1.520300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>1.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>1.522800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.535600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>1.623900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>1.569500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>1.581600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>1.515200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.587100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>1.608200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>1.546300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>1.556000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>1.557100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.554400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>1.569100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>1.571100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>1.540100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>1.521200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.566500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>1.623300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>1.583600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>1.579500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>1.568800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.570600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>1.601400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>1.544300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>1.549600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>1.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.569900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2900, training_loss=1.6051822116457182, metrics={'train_runtime': 2404.1778, 'train_samples_per_second': 1.206, 'train_steps_per_second': 1.206, 'total_flos': 7.62396412045337e+18, 'train_loss': 1.6051822116457182, 'epoch': 20.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
